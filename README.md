# 从零开始构建神经网络图像分类器
本项目实现了一个包含全连接层与批量归一化层的神经网络分类器，在CIFAR-10数据集上采用小批次训练，并采用SGD优化，训练模型实现图像分类。

# 数据处理
首先将原始图像数据进行标准化处理，并将图像标签进行独热编码，将训练集打乱顺序后，按照9:1的比例划分为训练集和验证集。

# 模型构建
这里设计一个三层神经网络，包含两个隐藏层，可进行前向传播，以及通过反向传播计算给定损失的梯度。该神经网络包含3个全连接层（FCN），支持自定义激活函数(ReLU/LeakyReLU/Sigmoid/Tanh)，支持自定义学习率、正则化强度、隐藏层大小等超参数。并在FCN之间添加了批量归一化层（BN），最终通过softmax函数转化为概率分布输出。

网络结构如下：输入->FCN1->BN1->FCN2->BN2->FCN3->softmax->输出。

其中，FCN的权重矩阵和偏置向量，以及BN的缩放因子和平移因子，均为可学习参数，通过SGD优化器进行参数更新优化。

# 模型训练
在训练过程中，采用小批次训练，每次训练使用一个批次（大小可自定义）的数据，进行前向传播并计算损失函数，然后进行反向传播，并使用SGD优化器进行参数更新。

训练进行多轮迭代，学习率逐渐衰减（衰减策略可选），并在验证集上进行模型评估，保存当前最优模型。

训练过程添加了早停机制，当验证集上的准确率连续若干轮没有提高时，停止训练。

# 参数查找
在该网络模型中，存在以下超参数：
隐藏层大小、学习率、正则化强度、学习率衰减率、批次大小、最大迭代次数、激活函数

为了找到最佳的超参数组合，这里使用了网格搜索的方法，定义每项超参数的候选值，对每个参数组合进行训练，记录准确率、训练时间等指标，比较验证集上的准确率。
由于时间原因，每个参数组合只训练了15轮（通过尝试可以发现此时部分模型已表现出收敛）。

